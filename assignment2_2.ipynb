{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ee9e1a-17d8-4376-a821-0853f26bb20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e79b4",
   "metadata": {},
   "source": [
    "The following two cells are a suggestion on accessing the files. You are free to ignore these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6180270-7ef2-4f8b-9979-d207ce098a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Dataset1/data.json\", \"r\") as f:\n",
    "    data_1 = json.load(f)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Dataset2/data.csv\", \"r\") as file:\n",
    "    for row in csv.DictReader(file):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad227bf3-112d-403b-88a7-1a0bbdfece7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement this!\n",
    "\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self,dataset_path, transform=None, target_transform=None):\n",
    "        self.data = self._read_json(dataset_path)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens  = self.data[idx]['tokens']\n",
    "        label = self.data[idx]['label']\n",
    "\n",
    "        if self.transform:\n",
    "            tokens = self.transform(tokens)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return tokens, label\n",
    "\n",
    "    def _read_json(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "        \n",
    "class TransformTokens(object):\n",
    "\n",
    "    def __init__(self,output_len):\n",
    "        self.output_len = output_len\n",
    "    \n",
    "    def __call__(self,tokens):\n",
    "        if not isinstance(tokens, torch.Tensor):\n",
    "            tokens = torch.tensor(tokens)\n",
    "\n",
    "        if len(tokens) > self.output_len:\n",
    "            tokens = tokens[:self.output_len]\n",
    "        \n",
    "        if len(tokens) < self.output_len:\n",
    "            tokens = F.pad(tokens, (0, self.output_len - len(tokens)), \"constant\", 0)\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036f2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size=32, shuffle=True):\n",
    "        super().__init__(dataset,batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33765577-f46c-410a-b04f-3ecbf983e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = TransformTokens(100)\n",
    "\n",
    "tokens_dataset = TokenDataset(dataset_path=\"Dataset1/data.json\",\n",
    "                              transform=padding)\n",
    "\n",
    "\n",
    "#Separate the dataset in train and test datasets at random\n",
    "train_tokens, test_tokens = random_split(tokens_dataset, [4000,1574])\n",
    "\n",
    "train_loader = TokenDataLoader(train_tokens, batch_size=6, shuffle=True) # Dataloader for the training part of the dataset only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ef4d6",
   "metadata": {},
   "source": [
    "Test correctness here (do not change the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8386581e-416c-435b-84f9-f4ccf8a5c00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1045,  1005,  1049,  6069,  2022,  2188,  2574,  1998,  1045,\n",
      "          2123,  1005,  1056,  2215,  2000,  2831,  2055,  2023,  4933,  4902,\n",
      "          3892,  1010,  1047,  1029,  1045,  1005,  2310,  6639,  2438,  2651,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19181, 24471,  8840, 12423,  4647, 18163,  4854, 15536,  2094,\n",
      "          1057,  1010,  1040,  3372,  2202,  2009,  5667,  1012,  1012,  2522,\n",
      "          2480,  2108,  4854,  2003,  1040,  2087, 24282,  1050,  2995,  2126,\n",
      "          1997,  4760,  2784, 12242,  1010,  2729,  1050, 11320,  2615,   999,\n",
      "          1012,  1012, 17710,  9284,  2850,  2158,  2850,  1012,  1012,  1012,\n",
      "          2031,  3835,  2154,  4830,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3554,  2007,  1996,  2088,  2003,  3733,  1010,  1057,  2593,\n",
      "          2663,  2030,  4558, 18411,  2954,  3070,  2007,  2070,  2487,  2040,\n",
      "          2003,  2485,  2000,  1057,  2003,  4487,  8873, 10841,  7096,  2065,\n",
      "          1057,  4558,  1011,  1057,  4558,  2065,  1057,  2663,  1011,  1057,\n",
      "          2145,  4558,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1054,  1057,  8434,  2033,  2005,  4596,  1029,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2031,  2017,  4201,  2115,  2250,  9834,  2240,  2000,  2717,\n",
      "          1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3432,  3564,  1998,  3666,  2674,  1999,  2436,  1012,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "tensor([0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19278914-52c8-4484-8bf7-fd4d9bdc3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement this!\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, dataset_path, transform = None, target_transform = None):\n",
    "        self.dataframe = pd.read_csv(dataset_path)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.dataframe.iloc[idx,-1]\n",
    "        symptoms = self.dataframe.iloc[idx,1:-1]       \n",
    "        symptoms = torch.tensor(symptoms, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            symptoms = self.transform(symptoms)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return symptoms, label\n",
    "\n",
    "class ConvertLabeltoInt(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.map = {'Lyme_disease':0,\n",
    "                    'Tungiasis':1,\n",
    "                    'Zika':2,\n",
    "                    'Rift_Valley_fever':3,\n",
    "                    'West_Nile_fever':4,\n",
    "                    'Malaria':5,\n",
    "                    'Chikungunya':6,\n",
    "                    'Plague':7,\n",
    "                    'Dengue':8,\n",
    "                        'Yellow_Fever':9,\n",
    "                    'Japanese_encephalitis':10}\n",
    "\n",
    "    def __call__(self, label):\n",
    "        \n",
    "        if isinstance(label, str):\n",
    "            label = self.map[label]\n",
    "        \n",
    "        return label\n",
    "    \n",
    "class CreateOnehotEncode(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, label):\n",
    "        target = torch.zeros(11, dtype=torch.float)\n",
    "        target.scatter_(dim=0, index = torch.tensor([label]), value=1)\n",
    "\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df6d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_transform = transforms.Compose([ConvertLabeltoInt(),CreateOnehotEncode()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76027a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size=32, shuffle=True):\n",
    "        super().__init__(dataset,batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c485899-0fe1-4cba-ae1b-a3c68c8f65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "desease_dataset = CSVDataset(dataset_path=\"Dataset2/data.csv\",\n",
    "                     target_transform=composed_transform)\n",
    "\n",
    "train_desease, test_desease = random_split(desease_dataset, [500,207])\n",
    "\n",
    "train_loader_desease = CSVDataLoader(train_desease, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71947ef",
   "metadata": {},
   "source": [
    "Test correctness here (do not change the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82343dbf-a775-472a-a263-282589271f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 64])\n",
      "torch.Size([6, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_331136\\2348956859.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  symptoms = torch.tensor(symptoms, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_loader_desease))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
